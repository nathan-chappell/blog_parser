- !Sample
  answer: font-face
  article_title: FontFace - custom fonts for your sites
  context: There are several approaches for integrating custom fonts to standards-compliant
    web pages - some of them use custom scripts (Cufon, sIFR, FLIR), and others use
    pure-CSS solutions, like @font-face. All of these technologies have valid arguments
    both for and against their use, but probably the most flexible and safest, and
    in general the best method for using various non-system fonts on your web site
    is @font-face.
  filename: 2012/01/24/FontFace-custom-fonts-for-your-sites/index.html
  question: what's the best way to use custom fonts on a website?
- !Sample
  answer: pick them up from various web sites
  article_title: FontFace - custom fonts for your sites
  context: The easiest way to get web fonts is to pick them up from various web sites
    that hold vast font repositories of free or commercial fonts.
  filename: 2012/01/24/FontFace-custom-fonts-for-your-sites/index.html
  question: what's the easiest way to get web fonts?
- !Sample
  answer: Missing cordova-2.2.0.jar file
  article_title: Building Cordova 2.2.0
  context: Missing cordova-2.2.0.jar file is causing the infamous The import org.apache.cordova
    cannot be resolved error. You should have Eclipse, Android SDK and the ADT plugin
    already installed on your machine, the PATH environment variables should be set
    up. Create a new project using
  filename: 2012/12/20/Building-Cordova-2-2-0/index.html
  question: what causes the error The import org.apache.cordova cannot be resolved
- !Sample
  answer: install the VirtualBox guest additions
  article_title: Installing Redmine and Ubuntu on VirtualBox
  context: After restarting the machine for the first time and logging in we need
    to install the VirtualBox guest additions to get access to all available features
    of the guest machine (mouse integration, full resolution, etc.). Just press Host+D
    or choose Install Guest Additions... action from Devices menu.
  filename: 2013/01/07/Installing-Redmine-and-Ubuntu-on-VirtualBox/index.html
  question: After installing virtualbox, what's the first thing you need to do?
- !Sample
  answer: Downloading and building Redmine from source is a preferred way to install
    it
  article_title: Installing Redmine and Ubuntu on VirtualBox
  context: Now we need to get Redmine source. Downloading and building Redmine from
    source is a preferred way to install it since we will benefit from the latest
    fixes and upgrades provided by the community. Subversion is included in Ubuntu
    and I'll use it to get latest source. You can find instructions for code checkout
    on the Redmine site Download section - just enter the command below and the last
    stable release will be checked out to subdolfer redmine-2.1
  filename: 2013/01/07/Installing-Redmine-and-Ubuntu-on-VirtualBox/index.html
  question: How should I install redmine on ubuntu?
- !Sample
  answer: it contains configuration settings
  article_title: Installing Redmine and Ubuntu on VirtualBox
  context: After downloading the code we need to modify a few configuration files
    in Redmine project to support our development environment. We will start with
    Gemfile, as it contains configuration settings for all required gems. I ended
    up with changing these lines to accommodate our environment
  filename: 2013/01/07/Installing-Redmine-and-Ubuntu-on-VirtualBox/index.html
  question: What is a Gemfile?
- !Sample
  answer: an open source C# library
  article_title: ASP.NET WebAPI, APNS and Android working together
  context: We will use an open source C# library called Moon-APNS to send messages
    to APNS. You can find more info on it on arashnorouzi blog. Just download the
    library from GitHub, add its project to the solution and add references to the
    Model project and Moon-APNS project from the ServerApp.
  filename: 2013/02/01/ASP-NET-WebAPI-APNS-and-Android-working-together/index.html
  question: What is moon-apns?
- !Sample
  answer: basically function pointers
  article_title: Delegates in action
  context: The main idea is to declare two delegates. As we all know, delegates in
    .NET are basically function pointers. The first one is used to reference a repository
    method, and the second references an action performed on each entity.
  filename: 2013/02/17/Delegates-in-action/index.html
  question: What are delegates in .NET?
- !Sample
  answer: Internet Explorer Mobile on Windows Phone 7.5
  article_title: Custom fonts using Cufon on Windows Phone
  context: Every major browser platform supports @font-face, except Internet Explorer
    Mobile on Windows Phone 7.5. This problem can be solved using Cufon, a javascript
    text-image replacement solution that combines HTML5 canvas and VML to render the
    fonts.
  filename: 2013/03/10/Custom-fonts-using-Cufon-on-Windows-Phone/index.html
  question: What browser does not support @font-face?
- !Sample
  answer: line-height
  article_title: Custom fonts using Cufon on Windows Phone
  context: 'There is one issue that remains to be solved: line-height css rule is
    not supported by Cufon. You can work around this limitation by'
  filename: 2013/03/10/Custom-fonts-using-Cufon-on-Windows-Phone/index.html
  question: Which css rules are not supported by cufon?
- !Sample
  answer: run it inside of a BEGIN TRANSACTION / ROLLBACK TRANSACTION block
  article_title: How to prevent data loss during delete update in SQL Server
  context: 'What if you have a large DB that takes long to back-up and you really
    don''t have that time? What if you absolutely must do the edit/update without
    backup. There is a way to test of the script is running fine: run it inside of
    a BEGIN TRANSACTION / ROLLBACK TRANSACTION block and add script that checks the
    results after the delete/update. I do this always, regardless if I have a backup
    or not'
  filename: 2013/04/22/How-to-prevent-data-loss-during-delete-update-in-SQL-Server/index.html
  question: How can I test an edit/ delete script without backup?
- !Sample
  answer: MVC 4
  article_title: Adding ASP.NET SimpleMembership to an existing MVC 4 application
  context: Even though there is an MVC 4 template for a new Internet project that
    contains membership functionality, some people like to start building their apps
    from an empty project.
  filename: 2013/05/07/Adding-ASP-NET-SimpleMembership-to-an-existing-MVC-4-application/index.html
  question: What template has membership functionality?
- !Sample
  answer: it isn't suppose to work that way
  article_title: Azure Mobile Services tips and tricks
  context: I'd like to start with Live SDK sample landing page for Windows Phone.
    There is a link to download it, and it says it's working on WP7. There is also
    a code sample. Great! Except, um, that's the code sample for WP8. Even though
    async and await are working on WP7, Live SDK isn't working with it. Why?! I was
    stuck until I found that it isn't suppose to work that way - you should use the
    event pattern instead.
  filename: 2013/05/27/Azure-Mobile-Services-tips-and-tricks/index.html
  question: Why doesn't Live SDK work on WP7?
- !Sample
  answer: set a single setting in your web.config
  article_title: 'Delegates in action, part 2: ASP.NET password encryption'
  context: Setting the password formats in ASP.Net is quite simple. All you need to
    do is to set a single setting in your web.config and you are ready to go. But
    what if you've already used Clear password format, your application is in a production
    environment, and you decide to change it to the Hashed password format? You cannot
    just change the PasswordFormat setting and expect that everything will work fine.
    You have to care of the old entries and convert them to the new password format.
  filename: 2013/06/10/Delegates-in-action-part-2-ASP-NET-password-encryption/index.html
  question: How do you set a password format in ASP.net?
- !Sample
  answer: make a database backup
  article_title: 'Delegates in action, part 2: ASP.NET password encryption'
  context: We strongly recommend you to make a database backup before you start playing
    either with password format conversion or some other data manipulation task.
  filename: 2013/06/10/Delegates-in-action-part-2-ASP-NET-password-encryption/index.html
  question: What should you do before changing the password format?
- !Sample
  answer: association of local software companies and independent contractors
  article_title: The Geek Gathering 2013
  context: The association of local software companies and independent contractors
    - known as Osijek Software City - now includes several hundred developers with
    different backgrounds and is growing stronger every month. Our goal is to put
    Osijek on a global IT industry map, and our members cover a large spectrum of
    different technologies, from Magento and LAMP stack, to Java and .NET.
  filename: 2013/10/17/The-Geek-Gathering-2013/index.html
  question: What is Osijek Software City?
- !Sample
  answer: handles file upload for you and lets you upload files asynchronously to
    the server
  article_title: Async upload using angular-file-upload directive and .NET WebAPI
    service
  context: Angular-file-upload directive is an awesome lightweight AngularJS directive
    which handles file upload for you and lets you upload files asynchronously to
    the server. This post will give you basic understanding on how to upload files
    by using this directive together with .NET WebAPI service.
  filename: 2013/12/08/Async-upload-using-angular-file-upload-directive-and-net-WebAPI-service/index.html
  question: What does angular-file-upload do?
- !Sample
  answer: Microsoft recently introduced Cross-Origin Resource Sharing (CORS) support
  article_title: Managing Azure CORS rules
  context: Microsoft recently introduced Cross-Origin Resource Sharing (CORS) support
    for Azure blobs, queues and tables.  This means you can now access Azure resources
    using AJAX-only calls from any domain which is quite handy. Imagine having a website
    hosted on your own server and allowing your users to upload large files to Azure
    Storage. Previously, you would need to upload and siphon all the data through
    your server and you would have to use Azure Storage SDK to do it. This means that
    processing time and bandwidth of your server are being wasted just for relaying
    data to its real destination. The good news is - you can now upload files to Azure
    Storage directly from the browser, using only client-side code and the Azure REST
    API, and without wasting additional server resources.
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: Why can you now access azure resources from any domain?
- !Sample
  answer: using the Azure SDK
  article_title: Managing Azure CORS rules
  context: 'To be able to upload files this way, you would of course need to enable
    CORS for a particular Azure Storage account you want to use. There are two tips
    that could save you time with this:  as far as I know, you can''t manage Azure
    CORS rules through the Azure management portal at this moment, it needs to be
    done using the Azure SDK'
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: How can you change Azure CORS rules?
- !Sample
  answer: using em dashes
  article_title: A simple and nice list Sass mixin using em-en dashes
  context: The default browser styles for the bulleted lists are a bit boring and
    not really pretty. Let's fix that up with a quick Sass mixin by using em dashes
    before the text.  Let's set up some basic variables first. The $list-nice-dash
    is an option between an en-dash and an em-dash respectively. Use $list-nice-generate-html-class
    variable for HTML class generation for the list (for further reuse).
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: How can you make bulleted lists prettier?
- !Sample
  answer: an URL
  article_title: Building Windows Azure Media Services async CORS enabled upload
  context: This brings us to the next point - when I say 'upload through WAMS', what
    I really mean by this is 'upload through a Shared Access Signature (SAS)'. SAS
    is basically an URL which we will create for each file (a video in our case) and
    it will be used to make consecutive AJAX upload requests against the Azure REST
    API. Each SAS has its validity duration and a permission type like read, write,
    list and delete. These will all be defined in the backend portion of the code.
    (if you want to know more about SAS, i recommend you read this great post about
    Azure SAS).
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: What is a shared access signature?
- !Sample
  answer: make consecutive AJAX upload requests
  article_title: Building Windows Azure Media Services async CORS enabled upload
  context: This brings us to the next point - when I say 'upload through WAMS', what
    I really mean by this is 'upload through a Shared Access Signature (SAS)'. SAS
    is basically an URL which we will create for each file (a video in our case) and
    it will be used to make consecutive AJAX upload requests against the Azure REST
    API. Each SAS has its validity duration and a permission type like read, write,
    list and delete. These will all be defined in the backend portion of the code.
    (if you want to know more about SAS, i recommend you read this great post about
    Azure SAS).
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: What is a shared access signature used for?
- !Sample
  answer: your upload PUT requests against Azure will be rejected
  article_title: Building Windows Azure Media Services async CORS enabled upload
  context: To upload files through an SAS URI, Cross-Origin Resource Sharing needs
    to be enabled over at Azure for your particular domain. If you don't enable CORS,
    your upload PUT requests against Azure will be rejected. You can read a bit more
    about managing Azure CORS rules in my previous post. Normally you would have to
    set the rules up through your source-code, but since this is a one-time set-up,
    it makes no sense to keep this code in your project. That's why we made a simple
    web app for managing Azure CORS rules which you can download over at github. It
    will make it easier for you to add/edit the rules.
  filename: 2013/12/28/Managing-Azure-CORS-rules/index.html
  question: What happens if you try to upload a file through a SAS URI without enabling
    CORS?
- !Sample
  answer: discovering new tricks and secrets about JavaScript, design, UX, cloud computing,
    databases, big data, Internet of things, Web application security, hybrid Web
    development and other cutting-edge software development topics.
  article_title: The Geek Gathering
  context: 'If the name still doesn''t sound familiar - The Geek Gathering is all
    about discovering new tricks and secrets about JavaScript, design, UX, cloud computing,
    databases, big data, Internet of things, Web application security, hybrid Web
    development and other cutting-edge software development topics. More details on
    its humble beginnings are available here. Mono was in charge of the content: we''ve
    been trying to bring world-class speakers to our part of the world, and according
    to the feedback, it appears that we did a good job.'
  filename: 2014/05/19/The-Geek-Gathering/index.html
  question: What is the purpose of the geek gathering?
- !Sample
  answer: Douglas Crockford
  article_title: The Geek Gathering
  context: The conference was opened by the man himself, Douglas Crockford. His talk,
    'The Better Parts' was one of those out-of-the-box experiences. Many of us swear
    by his book, and were simultaneously surprised and inspired by his views on the
    new features in ECMAScript 6. I still don't have production-quality videos from
    this year's conference, so here's a good quality recording of the same talk he
    held at the neighboring conference just a month ago, and believe me, you don't
    want to miss it.
  filename: 2014/05/19/The-Geek-Gathering/index.html
  question: Who opened the Geek Gathering in 2014?
- !Sample
  answer: slow rendering speed (always) huge amount of watchers
  article_title: Improving AngularJS long list rendering performance using ReactJS
  context: 'There are two problems with generating long lists in Angular:  slow rendering
    speed (always) huge amount of watchers (if your list contains multiple interactive
    elements or lots of dynamic data that changes over time)'
  filename: 2014/06/20/Improving-AngularJS-long-list-rendering-performance-using-ReactJS/index.html
  question: What are the problems loading long lists in Angular?
- !Sample
  answer: around 2000
  article_title: Improving AngularJS long list rendering performance using ReactJS
  context: Slow rendering will make it longer for the data to actually show up in
    the browser (on initial and every subsequent render) and huge amount of watchers
    will make your website laggy and less responsive in general once everything is
    rendered. Keep in mind that recommended amount of watchers per page is around
    2000. So if your list is not that long but 'only' has a lot of watchers, you might
    be able to work around the problem using bindonce which will significantly decrease
    the number of watchers on your page. If your list however is quite long, rendering
    it will take some time.
  filename: 2014/06/20/Improving-AngularJS-long-list-rendering-performance-using-ReactJS/index.html
  question: What is the recommended number of watchers in Angular?
- !Sample
  answer: a Reacts compiler
  article_title: Improving AngularJS long list rendering performance using ReactJS
  context: React-tools will provide you with JSX which is a Reacts compiler that transforms
    its JS/XML-like syntax into native JavaScript. To write ReactJS components you
    will need an empty JS file with the following line at the beginning of the file
    /** @jsx React.DOM */ and any ReactJS components code bellow that. After you run
    the JSX watcher (jsx --watch jsx_folder/ scripts_folder/) on folder where that
    JS file resides in it will look for changes and (re)create a second (native JS)
    file which you will need to include into your project.
  filename: 2014/06/20/Improving-AngularJS-long-list-rendering-performance-using-ReactJS/index.html
  question: What is JSX?
- !Sample
  answer: one of the most popular and well rounded JS promise libraries with NodeJS
    support
  article_title: Creating NodeJS modules with both promise and callback API support
    using Q
  context: However, you might also want to support the error-first callback pattern
    as well, for all the developers out there who prefer to use the standard NodeJS
    approach. Since Q is currently one of the most popular and well rounded JS promise
    libraries with NodeJS support, in this post we'll be using Q to implement a module
    function that will support dual promise/callback API's.
  filename: 2014/07/07/Creating-NodeJS-modules-with-both-promise-and-callback-API-support-using-Q/index.html
  question: What is Q?
- !Sample
  answer: real-time communication
  article_title: Sharing sessions between SocketIO and Express using Redis
  context: Even if you're using SocketIO, chances are you don't really need all your
    communication between the client and the server to go through sockets. For all
    the parts of your application that require real-time communication SocketIO will
    be perfect but for everything else you might be better off using standard REST
    API calls. Why? Without going into 'speed' and 'ease of implementation' pros and
    cons (there's plenty of that lying around the Internet) I see a few reasons why
    one might want to use both in the same application. REST is still a bit more 'standard'
    way to exchange data and if there is no real need to use websockets everywhere,
    your team might be a bit more comfortable using REST since it's what they've been
    using 'ever since'. Other than that, you might be in the middle of a project that
    previously used REST for everything and now the need arose to develop a component
    which requires real-time communication. Of course, you won't be rewriting all
    your code to SocketIO because there are more important things to dedicate your
    time to. Or you might simply believe SocketIO should be in charge of everything
    real-time and REST should be used to handle everything else - which is also perfectly
    fine. Either way, you'll most probably get into situation where you'll want to
    share session data between the two.
  filename: 2014/08/25/Sharing-sessions-between-SocketIO-and-Express-using-Redis/index.html
  question: What parts of an application is SocketIO best suited for?
- !Sample
  answer: Great products and code Human centric design Quality as a tradition
  article_title: Redesigning the Mono experience
  context: 'The initial step for achieving better communication was redesigning the
    way we present Mono to the world. The time was right for redesigning our visual
    identity so it reflects our company values:  Great products and code Human centric
    design Quality as a tradition'
  filename: 2015/01/08/Mono-a-redesigned-experience/index.html
  question: What are mono's company values?
- !Sample
  answer: too cold and generic
  article_title: Redesigning the Mono experience
  context: We have done a lot of desk research and discussions on the logical evolutionary
    steps for our visual identity. The result was clear -- we wanted to keep the core
    idea of a 'pixel' that was a cornerstone of our old visual identity. It is a good
    representation of the digital world, but we felt it did not represent our brand
    good enough on its own - however, we've decided to use it as a core element of
    the new design. The pixel, along with the blue color scheme was way too cold and
    generic, so that had to go away. To achieve a warmer, more human approach we changed
    our brand colors to vibrant red and elegant black.
  filename: 2015/01/08/Mono-a-redesigned-experience/index.html
  question: Why did mono change their visual identify from a pixel and blue color
    scheme?
- !Sample
  answer: add new value to our clients, users and the community
  article_title: A new place called home
  context: Over the last couple of months we've been working hard on our new visual
    identity and the new Mono website. Today is the day where we share the results
    of this work with the rest of the world.  The idea behind the new site is to add
    new value to our clients, users and the community. Take your time to find out
    about our new products such as Baasic and Theor.io, or see what's been happening
    lately with MonoX and eCTD Office. You can meet the team and see what we've accomplished
    over the years.
  filename: 2015/01/09/A-new-place-called-home/index.html
  question: Why did mono make a new website?
- !Sample
  answer: how users percieve it
  article_title: Importance of photography in web design
  context: Quality and reliability of the website design largely depends on how users
    percieve it. Good photography and visual design guides the users and communicates
    an atmosphere around a certain brand or product.
  filename: 2015/02/05/Importance-of-photography-in-web-design/index.html
  question: What does quality and reliability of a website design depend on?
- !Sample
  answer: guides the users and communicates an atmosphere
  article_title: Importance of photography in web design
  context: Quality and reliability of the website design largely depends on how users
    percieve it. Good photography and visual design guides the users and communicates
    an atmosphere around a certain brand or product.
  filename: 2015/02/05/Importance-of-photography-in-web-design/index.html
  question: What does good photography do for a brand?
- !Sample
  answer: Professional photographers are already familiar with lightning, they know
    their camera really well and don't lack in equipment that is too expensive for
    an amateur
  article_title: Importance of photography in web design
  context: The best and most recommended option is to hire a pro. If you have a team
    member who is a semi-pro or an amateur photographer with a good set of lens and
    a DSLR you can take a walk on the wild side and make your own photos. Professional
    photographers are already familiar with lightning, they know their camera really
    well and don't lack in equipment that is too expensive for an amateur. On the
    other hand, hiring a professional does not guarantee quality of your photo story.
    Sometimes the story is not very well told by the photographer, sometimes the lightning/colours/tone
    in the photographs doesn't reflect your brand or product. Those things happen
    commonly so make sure you communicate your expectations and your brand with the
    professional down to the detail. Put pros and cons on paper and decide what is
    best for your project.
  filename: 2015/02/05/Importance-of-photography-in-web-design/index.html
  question: Why should you hire a pro photographer?
- !Sample
  answer: Baasic provides a standard set of backend features
  article_title: Baasic beta now opened
  context: 'Here is a short introduction to this new product/service: Baasic provides
    a standard set of backend features - after all, BaaS in its name does not stand
    for nothing. For those of you not familiar with this term, please refer to our
    introductory article. However, this is only a beginning: Baasic hits a sweet spot
    on the intersection of today''s BaaS solutions, content management systems and
    modern application frameworks. It offers end-to-end functionality for web and
    mobile application development that is not tied to a particular programming language
    and development framework.'
  filename: 2015/03/24/Baasic-beta-now-opened/index.html
  question: What is Baasic?
- !Sample
  answer: Baasic provides a standard set of backend features
  article_title: Baasic beta now opened
  context: 'Here is a short introduction to this new product/service: Baasic provides
    a standard set of backend features - after all, BaaS in its name does not stand
    for nothing. For those of you not familiar with this term, please refer to our
    introductory article. However, this is only a beginning: Baasic hits a sweet spot
    on the intersection of today''s BaaS solutions, content management systems and
    modern application frameworks. It offers end-to-end functionality for web and
    mobile application development that is not tied to a particular programming language
    and development framework.'
  filename: 2015/03/24/Baasic-beta-now-opened/index.html
  question: What is Baasic?
- !Sample
  answer: not having a link to the EULA along with uninstall instructions somewhere
    at the download page
  article_title: When Google says your software is unwanted
  context: A short Google search revealed that there are not too many resources regarding
    this problem - I guess that this will change very soon. However, one post from
    the guys from HttpWatch was particularly informative and entertaining, and quickly
    got us into the right track. It appears that not having a link to the EULA along
    with uninstall instructions somewhere at the download page will immediately classify
    your software as 'unwanted'. We still think that it is important for a software
    company to have all terms and conditions displayed in plain sight, without loopholes,
    ambiguity or small print; however, there should be a gentler way to handle the
    issue of positioning links to such documents.
  filename: 2015/04/23/Google-unwanted-software/index.html
  question: What can cause your software to be classified as unwanted?
- !Sample
  answer: it cannot scale out horizontally
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: While we've used SQL Server in most of our previous implementations, after
    doing some preliminary tests, PostgreSQL proved to be a very capable relational
    database. After all, it has millions of implementations over its 30-year history.
    It is still being kept very relevant in the big data era by adding support for
    new data types, such as JSON - a feature that is essential for implementing dynamic
    types and similar functionality in Baasic and similar solutions. The capability
    to handle schema-less data simultaneously with traditional relational data is
    a big plus for us. However, as most of traditional RDBMSes designed to power transactional
    workloads, it cannot scale out horizontally (at least without specialized add-ons).
    When resources become thin, you would buy a bigger server, instead of scaling
    the load out to multiple smaller machines. While scale-out approach is becoming
    increasingly popular these days (mostly in various NoSQL incarnations), I would
    still argue that scaling up is a viable solution for a large class of problems.
    If you need to scale on a Google scale, scale out is the right way to go. However,
    we are not Google, and neither are most of the web sites and applications.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: Can postgresql scale horizontally?
- !Sample
  answer: avoid it at all costs
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: To quote one of the posters at stackexchange, 'first rule of horizontal
    scaling of a database is to avoid it at all costs.'.  If you still need to scale
    out, there are now a few interesting solutions for SQL Server and Azure SQL Database.
    PostgreSQL has its own tools for the job, including CitusDB and Postgres-XL.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: What is the first rule of horizontally scaling a database?
- !Sample
  answer: Shoot The Other Node In The Head
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: In our case, we needed full support for failover - in a two DB servers
    scenarios, if the primary server fails then the standby server should begin failover
    procedures. On a side note, this is probably the right time to introduce concepts
    of cold, warm and hot standby nodes. So, when the old primary server restarts,
    we must have a mechanism for informing the old primary that it is no longer the
    primary. This is known as STONITH (Shoot The Other Node In The Head), and is essential
    to avoid situations where both systems think they are the primary, which is a
    sure recipe for disaster, split-brain scenario and, ultimately, data loss. On
    the other hand, attempts to use PostgreSQL in multi-master shared storage configurations
    result in extremely severe data corruption. To make things more interesting, PostgreSQL
    does not provide the tools required to identify a failure on the primary and notify
    the standby database server out of the box. We did some research and tested a
    lot of tools for solving this problem, and while some users are perfectly happy
    with their choices, we were somewhat reluctant. In addition to that, running Windows
    version of PostgreSQL in a production environment is really not the best idea
    - and we already had a set of Windows Server 2012 R2 Servers with Hyper-V role
    as a software infrastructure for a virtualized environment. Database servers are
    running Linux, as multiple flavors of it are supported for use as a guest operating
    system in a Hyper-V virtual machine.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: What does STONITH stand for?
- !Sample
  answer: attempts to use PostgreSQL in multi-master shared storage configurations
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: In our case, we needed full support for failover - in a two DB servers
    scenarios, if the primary server fails then the standby server should begin failover
    procedures. On a side note, this is probably the right time to introduce concepts
    of cold, warm and hot standby nodes. So, when the old primary server restarts,
    we must have a mechanism for informing the old primary that it is no longer the
    primary. This is known as STONITH (Shoot The Other Node In The Head), and is essential
    to avoid situations where both systems think they are the primary, which is a
    sure recipe for disaster, split-brain scenario and, ultimately, data loss. On
    the other hand, attempts to use PostgreSQL in multi-master shared storage configurations
    result in extremely severe data corruption. To make things more interesting, PostgreSQL
    does not provide the tools required to identify a failure on the primary and notify
    the standby database server out of the box. We did some research and tested a
    lot of tools for solving this problem, and while some users are perfectly happy
    with their choices, we were somewhat reluctant. In addition to that, running Windows
    version of PostgreSQL in a production environment is really not the best idea
    - and we already had a set of Windows Server 2012 R2 Servers with Hyper-V role
    as a software infrastructure for a virtualized environment. Database servers are
    running Linux, as multiple flavors of it are supported for use as a guest operating
    system in a Hyper-V virtual machine.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: What can cause extreme data corruption in postgresql?
- !Sample
  answer: a group of servers
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: A failover cluster is a group of servers that work together to maintain
    high availability of applications and services (these are known as roles). If
    one of the servers (or nodes) fails, another node in the cluster can take over
    its workload without any downtime. In addition, the clustered roles are monitored
    to verify that they are working properly. If they are not working, they are restarted
    or moved to another node. Failover clusters also provide Cluster Shared Volume
    (CSV, more on that later) functionality that provides a consistent, distributed
    namespace that clustered roles can use to access shared storage from all nodes.
    Using this technology, you can scale up to 64 physical nodes and to 8,000 virtual
    machines.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: What is a failover cluster?
- !Sample
  answer: up to 64
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: A failover cluster is a group of servers that work together to maintain
    high availability of applications and services (these are known as roles). If
    one of the servers (or nodes) fails, another node in the cluster can take over
    its workload without any downtime. In addition, the clustered roles are monitored
    to verify that they are working properly. If they are not working, they are restarted
    or moved to another node. Failover clusters also provide Cluster Shared Volume
    (CSV, more on that later) functionality that provides a consistent, distributed
    namespace that clustered roles can use to access shared storage from all nodes.
    Using this technology, you can scale up to 64 physical nodes and to 8,000 virtual
    machines.
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: How many physical nodes can a failover cluster handle?
- !Sample
  answer: an abstract representation of multiple routers
  article_title: Windows Server 2012 clustering for high availability, with ASP.NET
    and PostgreSQL - Part 1
  context: 'Just to briefly mention the rest of the network infrastructure (firewalls,
    routers and load balancers) in front of these servers. Everything is set up in
    a redundant fashion. Therefore, firewalls/routers are using Virtual Router Redundancy
    Protocol (VRRP) that introduce a concept of virtual routers, which are an abstract
    representation of multiple routers - master and backup - acting as a group. When
    an active routers fails, a backup router is automatically selected to replace
    it. In a similar fashion, we are using multiple HAProxy load balancers, along
    with multiple A DNS records for our service employing round robin technique. There
    are multiple approaches for achieving the full redundancy and avoiding single
    point of failure in this type of environment: for example, Stackoverflow apparently
    uses keepalived to ensure high availability; heartbeat is also an alternative.
    We opted for an alternative approach that combines DNS load balancing - which
    achieves a fairly rough balance of traffic between multiple load balancers and
    enable failover when one of load balancer dies - and using load balancers to do
    their job on a more granular level. ''DNS Load Balancing and Using Multiple Load
    Balancers in the Cloud'' and ''How To Configure DNS Round-Robin Load-Balancing
    For High-Availability'' describe ''our'' approach in more details.'
  filename: 2015/09/04/Windows-Server-2012-Hyper-V-Cluster-ASP-NET-PostgreSQL-our-experiences-1/index.html
  question: What is a virtual router?
- !Sample
  answer: the Json.NET serializer
  article_title: JSON serialization caching
  context: In this post, I will not introduce yet another super-fast serializer. I
    also promise not to rely on quick and dirty techniques to enhance the existing
    ones. I will introduce a pretty simple mechanism which will allow you to optimize
    Json serialization output. It is important to point out that the proposed solution
    will be made on top of the Json.NET serializer which is already one of the fastest
    serializers out there. The technique presented here should also be applicable
    to all other serializers.
  filename: 2015/10/07/Json-serialization-caching/index.html
  question: What is a fast json serializer?
- !Sample
  answer: .Net's garbage collector
  article_title: JSON serialization caching
  context: On top of that, a graph has a few spikes, which look strange. After some
    time spent on the subject, we realized that the spikes are caused by the .Net's
    garbage collector which kicked in and caused a little serialization time discrepancy.  In
    the next two figures, you could see the performance results made on a 1000 and
    10000 weather stations, with a 50000 and 500000 weather readings, respectively.
  filename: 2015/10/07/Json-serialization-caching/index.html
  question: What causes the spikes in the serialization graph?
- !Sample
  answer: two
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 2: Prerequisites'
  context: The basic setup includes two servers running Hyper-V hypervisor and a Storage
    Area Network (SAN) as a shared storage mechanism. Additional Hyper-V servers can
    easily be added to achieve better scalability. In our scenario, each server contains
    4 Gigabit network adapters (NICs) and one Fibre Channel adapter (or host bus adapter,
    HBA). This FC adapter is used to connect with the SAN.
  filename: 2016/01/25/Hyper-V-Failover-Cluster-2/index.html
  question: How many servers run a Hyper-V hypervisor?
- !Sample
  answer: PostgreSQL databases
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 2: Prerequisites'
  context: 'We are creating multiple volumes on our SAN that will serve different
    purposes: - SystemStorage volume will hold the system disk of our database server.
    - DatabaseStorage will be used to store PostgreSQL databases. - FileStorage will
    be exposed to the application servers as a central shared location where users
    can store and share files. - Witness will be used for failover cluster quorum
    configuration'
  filename: 2016/01/25/Hyper-V-Failover-Cluster-2/index.html
  question: On the SAN, what does the DatabaseStorage volume store?
- !Sample
  answer: Hyper-V
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 2: Prerequisites'
  context: Basic installation and networking For a start, you will need to add the
    Hyper-V role to the servers. In Server Manager - Manage menu, click Add Roles
    and Features, select Role-based or feature-based installation, select the appropriate
    server, and pick Hyper-V on the Select server roles page. Leave all the default
    options on subsequent pages, and the Hyper-V role will get installed.
  filename: 2016/01/25/Hyper-V-Failover-Cluster-2/index.html
  question: What role needs to be added to the servers in Hyper-V clusters?
- !Sample
  answer: at least two separate NICs
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 2: Prerequisites'
  context: 'Is is always a good idea to use at least two separate NICs in failover
    clustering scenarios: the public interface is configured with the IP address that
    will be used to communicate with clients over the network, while the private interface
    is used for communicating with other cluster nodes (''heartbeat''). We will use
    an additional NIC for backup purposes - although this is not absolutely necessary,
    it will offload the traffic caused by regular backup tasks from the public interface.
    This leaves us with one free NIC, and we''ve decided to team two NICs on a main
    public interface. NIC team is basically a collection of network interfaces that
    work together as one, providing bandwidth aggregation and redundancy. It is easy
    to team NICs in Windows Server 2012, so I will not provide a step by step instructions
    on how to do that: here is an excellent article on NIC teaming that will guide
    you through the process. It is not a mandatory step for setting up a failover
    cluster.'
  filename: 2016/01/25/Hyper-V-Failover-Cluster-2/index.html
  question: How many NICs should be used in failover clustering?
- !Sample
  answer: Failover clustering is available in both Standard and Datacenter editions
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 3: Installation'
  context: Failover clustering is available in both Standard and Datacenter editions
    of Windows Server 2012 R2. Generally speaking, clustering involves using two or
    more physical servers to create one 'logical' server that exposes some functionality
    to users or applications. The members of the cluster (called nodes) are able to
    monitor each other and, if one of them goes down, its functionality 'fails over'
    to other nodes without causing any disruption of service to the users.
  filename: 2016/01/28/Hyper-V-Failover-Cluster-3/index.html
  question: Is Failover Clustering available in the standard edition of Windows Server
    2012?
- !Sample
  answer: Microsoft does not provide support unless all the hardware passes all the
    tests
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 3: Installation'
  context: 'After the failover clustering feature is added, you need to validate the
    environment in which you will create a cluster. This is an essential step: Microsoft
    does not provide support unless all the hardware passes all the tests in the validation
    wizard. You can set up a cluster without validating the hardware, but chances
    are that you will experience problems sooner or later, so it does not make a lot
    of sense. So, go to the Failover Cluster Manager and click on the Validate Configuration
    link in the Management pane.'
  filename: 2016/01/28/Hyper-V-Failover-Cluster-3/index.html
  question: Why do you need to validate your cluster environment after adding the
    failover clustering feature?
- !Sample
  answer: make sure that your SAN is supported
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 3: Installation'
  context: You can also add more disks at any time by clicking on the Add Disk option
    in the Actions pane of the Disks section. If you receive an error saying 'No disks
    suitable for cluster disks were found', make sure that your SAN is supported (validation
    process should report if it is not) and that your disks are initialized, visible
    on all nodes and have drive letter assigned to them. Alternatively, if you are
    using iSCSI targets, do not forget to configure the volumes at the iSCSI initiator
    on each node (Auto Configure button in the Volumes and Devices tab in the iSCSI
    Initiator Properties).
  filename: 2016/01/28/Hyper-V-Failover-Cluster-3/index.html
  question: 'What should you do if you get the error: No disks suitable for cluster
    disks were found'
- !Sample
  answer: Cluster Shared Volumes
  article_title: 'Windows Server 2012 Hyper-V Failover Clustering - Part 3: Installation'
  context: 'CSV (Cluster Shared Volumes) is a feature in Windows Server in which shared
    disks are concurrently accessible to all nodes within a failover cluster. You
    need to tell the cluster manager which storage should be used for the CSVs. In
    our scenario, we will use CSVs to hold disks for fault-tolerant virtual machines.
    As mentioned in the previous post, our standard arrangement involves something
    like this: - SystemStorage volume will hold the system disk of our database server.
    - DatabaseStorage will be used to store PostgreSQL databases. - FileStorage will
    be exposed to the application servers as a central shared location where users
    can store and share files. - Witness will be used for failover cluster quorum
    configuration.'
  filename: 2016/01/28/Hyper-V-Failover-Cluster-3/index.html
  question: What feature in Windows Server makes shared disks concurrently accessible
    to all nodes in a failover cluster?
- !Sample
  answer: early as 2008
  article_title: SEO for JavaScript applications, 2016 edition
  context: 'Traditionally, search engine crawlers were only looking at the raw textual
    content contained within the HTTP response body and didn''t really interpret what
    a typical browser running JavaScript would interpret. When pages that have a lot
    of content rendered by JavaScript started showing up, Google started crawling
    and indexing it as early as 2008, but in a rather limited fashion. Ajax crawling
    scheme was a standard, albeit clunky solution for this problem up until now. Google
    was putting a lot of work into a more elegant approach to understand web pages
    better, and finally, on Oct 14, 2015 they officially announced that the AJAX crawling
    scheme is now deprecated. In their own words:  We are no longer recommending the
    AJAX crawling proposal we made back in 2009.'
  filename: 2016/02/18/SEO-for-javascript-applications/index.html
  question: When did google start indexing content rendered by javascript?
- !Sample
  answer: serve the prerendered HTML snapshot
  article_title: SEO for JavaScript applications, 2016 edition
  context: 'letting you know that you should handle the response differently inside
    your JS application. On most occasions, you will serve the prerendered HTML snapshot
    to the crawler, saving it from the effort of parsing and executing JavaScript
    on its own.  The newer HTML5 pushState doesn''t work the same way, as it modifies
    the browser''s URL and history. If you are using pushState, you should use the
    following tag in the header of your pages:'
  filename: 2016/02/18/SEO-for-javascript-applications/index.html
  question: What can you do to save a crawler from the effort of executing javascript
    on its own?
- !Sample
  answer: prerendering services
  article_title: Installing Prerender.io
  context: As described in our previous article on SEO for JavaScript applications,
    prerendering services still play an important role in enabling search engine crawlers
    to index the dynamic content. This time we will learn how to install Prerender.io
    on your server infrastructure.
  filename: 2016/02/22/Installing-Prerender-io/index.html
  question: What enables search engines to index dynamic content?
- !Sample
  answer: optimize your JavaScript applications for search engines
  article_title: Installing Prerender.io
  context: Prerender.io is a great service that allow you to optimize your JavaScript
    applications for search engines without an effort - you just purchase an account
    with them and install the middleware on your server. The source code for their
    service is available on GitHub and you can alternatively run it from your servers
    which is handy in high-volume scenarios. This is what we are using for our applications,
    and since the installation instructions are a bit terse, we've decided to document
    the whole process. We will be using a fresh and dedicated installation of Ubuntu
    14.04 to run our local instance of Prerender.io.
  filename: 2016/02/22/Installing-Prerender-io/index.html
  question: What does prerender.io do?
- !Sample
  answer: it offers scalability and a simple cache expiration mechanism
  article_title: Installing Prerender.io
  context: Generating HTML snapshots is a resource-intensive process, so some sort
    of caching strategy should be used to improve the performance. Prerender.io comes
    with several different caching plugins, but we will use the one based on Redis,
    as it offers scalability and a simple cache expiration mechanism. Redis can be
    built from source, but the pre-built version is sufficient for the task at hand.
  filename: 2016/02/22/Installing-Prerender-io/index.html
  question: Why would you use the redis caching plugin?
- !Sample
  answer: to reuse instances within the lifetime of a scope (ambient instances) and
    to specify a deterministic dispose of resources
  article_title: Ninject ambient scope and deterministic dispose
  context: When working with Ninject, one can specify standard lifetime designators
    like InSingletonScope and InTransientScope in the bindings section. There are
    two important situations when one might want to define a custom scope - to reuse
    instances within the lifetime of a scope (ambient instances) and to specify a
    deterministic dispose of resources when a scope lifetime ends.
  filename: 2016/04/21/Ninject-ambient-scope-and-deterministic-dispose/index.html
  question: When would you define a custom lifetime or scope?
- !Sample
  answer: propagating its context
  article_title: Ninject ambient scope and deterministic dispose
  context: In order for the whole thing to work in the InNamedScope example above,
    BarFactory (or in a real life situation, a really complex chain of objects) needs
    to be injected by the parent scoping type (Foo or Goo or Moo) because that's under
    Ninject's control and that's the only way it can pass the contextual parent scope
    information down to the injection chain. As soon as one moves away from the NamedScope
    extension way of doing things, the biggest challenge in accomplishing Ninject
    to be aware of a custom scope is not wiring it in the bindings, but actually propagating
    its context in an async/await environment.
  filename: 2016/04/21/Ninject-ambient-scope-and-deterministic-dispose/index.html
  question: What's the biggest challenge in making ninject aware of a custom scope?
- !Sample
  answer: have that scope implement the Ninject's INotifyWhenDisposed interface
  article_title: Ninject ambient scope and deterministic dispose
  context: 'Amazingly, googling Ninject deterministic dispose gives various confusing
    posts, so one may need to dig further to find a coherent answer. I found it nicely
    explained in this old article - Cache-and-Collect Lifecycle Management in Ninject
    2.0. It seems that the only way to have a deterministic dispose of an instance
    bound to a custom scope is to have that scope implement the Ninject''s INotifyWhenDisposed
    interface. It will immediately cause the disposal of any IDisposable instance
    associated with the scope object when scope''s Dispose method is invoked. The
    key thing is to raise the INotifyWhenDisposed.Disposed event within the Dispose
    method. Here''s the code for the universal disposable scope:'
  filename: 2016/04/21/Ninject-ambient-scope-and-deterministic-dispose/index.html
  question: How can you deterministically dispose of an instance bound to a custom
    scope?
- !Sample
  answer: (AWS) provides a platform that is well suited for building fault-tolerant
    software
  article_title: Building highly available applications with Amazon RDS
  context: Amazon Web Services (AWS) provides a platform that is well suited for building
    fault-tolerant software. Similar services are offered by other cloud providers,
    and most of them provide the infrastructure needed for building fault-tolerant
    systems that operate with a minimal amount of human interaction and up-front financial
    investment. We have chosen AWS because of its sheer size, popularity, and price
    structure. More importantly, we were looking to avoid complicated and time-consuming
    administrative tasks such as database installation and upgrades; storage management;
    replication for high availability and read throughput; and backups for disaster
    recovery. Over the past few years, PostgreSQL has become the preferred open source
    relational database for many developers, and we are using it in most of our new
    applications. Amazon Relational Database Service (RDS) makes it easy to set up,
    operate, and scale PostgreSQL databases in the cloud, and provides support for
    Amazon Aurora, MySQL, MariaDB, Oracle and SQL Server too. It is an ideal choice
    for both smaller shops without an experienced DBA, and larger organizations that
    need to scale their solutions.
  filename: 2016/07/13/Building-highly-available-applications-with-Amazon-RDS/index.html
  question: What does AWS do?
- !Sample
  answer: Amazon Virtual Private Cloud
  article_title: Building highly available applications with Amazon RDS
  context: Amazon Virtual Private Cloud (VPC) lets you provision a logically isolated
    section of the 'big' Amazon cloud where you can launch AWS resources in a virtual
    network that you define. Since our database instance only needs to be available
    to the web server - and not to the public Internet - we create a VPC with both
    public and private subnets. The web server will be hosted in the public subnet.
    The database instance will be hosted in a private subnet. The web server will
    be able to connect to the database instance because it is hosted within the same
    VPC, but the database instance will not be available to the public Internet, providing
    greater security.
  filename: 2016/07/13/Building-highly-available-applications-with-Amazon-RDS/index.html
  question: What let's you use AWS resources in a virtual network?
- !Sample
  answer: an infrastructure failure
  article_title: Building highly available applications with Amazon RDS
  context: A word about Multi-AZ deployments, which turns out to be one of the coolest
    database features we use in the AWS. When you provision a Multi-AZ DB Instance,
    Amazon automatically creates a primary DB Instance and synchronously replicates
    the data to a standby instance in a different Availability Zone. Each AZ has its
    own physically distinct infrastructure. In the case of an infrastructure failure,
    Amazon RDS performs an automatic failover to the standby, so that you can resume
    database operations as soon as the failover is complete - in our initial tests,
    this takes less than a minute. Since the endpoint for your DB Instance remains
    the same after a failover, your application can resume database operation without
    the need for any manual intervention.
  filename: 2016/07/13/Building-highly-available-applications-with-Amazon-RDS/index.html
  question: What causes Amazon RDS to automatically perform a failover?
- !Sample
  answer: Amazon ElastiCache
  article_title: Building highly available applications with Amazon RDS
  context: Amazon ElastiCache is a web service that makes it easy to deploy, operate,
    and scale an in-memory cache. It supports two open-source in-memory caching engines,
    Memcached and Redis. We are using Redis in our projects, and ElastiCache supports
    Master / Slave replication and Multi-AZ, which can be used to achieve cross zone
    redundancy.
  filename: 2016/07/13/Building-highly-available-applications-with-Amazon-RDS/index.html
  question: What web service supports the redis in-memory caching engine?
- !Sample
  answer: plain JavaScript
  article_title: Please move, here comes Angular 2
  context: If you are using AngularJS as your UI framework, be prepared, Angular 2
    delivers a substantial change. No more plain old JavaScript - say hi to Typescript.
    Well, Angular 2 can be written in JavaScript, Typescript, and Dart, but sympathy
    mostly goes to Typescript as it is the language Angular 2 was written in. Although
    it does eventually compile to plain JavaScript, Typescript is a powerful language
    that lets you build things that would otherwise take time and time to do. What
    you're actually doing with Angular 2 is writing templates in Typescript. Angular
    2 then turns that templates into code that's highly optimized for today's JavaScript
    virtual machines, says the Angular 2 team, but more on that later.
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: What does typescript compile to?
- !Sample
  answer: components
  article_title: Please move, here comes Angular 2
  context: Angular 2 is entirely component based; there are no $scopes or controllers.
    Instead, you are writing small chunks of code that are later connected to form
    one big application. Those small chunks of code are components - below you can
    see an example of one. The component is defined by the @Component decorator, and
    each one has its own custom selector (HTML tag), template (or template URL for
    external template), directives, providers, and pipes (which we'll talk about later).
    Each component also has its own class called component class. In order to use
    (import) it somewhere else, we have to export it.
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: What are the small chunks of code called which later are connected to
    form the application?
- !Sample
  answer: Component
  article_title: Please move, here comes Angular 2
  context: 'As for the naming convention, each component name ends with Component,
    and the name of the file that holds it with .component. All the files are in kebab-case,
    so no worries about case sensitivity. Applied to the example component above,
    the file name would look like this: my-custom.component.ts.'
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: What do all Angular component names end with?
- !Sample
  answer: the ones that change the appearance or behavior of an element they are applied
    to
  article_title: Please move, here comes Angular 2
  context: Attribute directives are the ones that change the appearance or behavior
    of an element they are applied to. These directives are specified by their selector
    using square brackets (read more about attribute directives here).  Structural
    directives are here to add, remove, and replace elements in DOM. If you used AngularJS,
    you have seen them or used them plenty of times. Like in AngularJS, ng-if and
    ng-repeat exist in Angular 2 too, but are slightly changed. Structural directives
    now start with a '*'(*ngFor, *ngIf). If you see that in an HTML code, that is
    a structural directive (read more about structural directives here).
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: What are attribute directives?
- !Sample
  answer: AppComponent
  article_title: Please move, here comes Angular 2
  context: What is also new is that there is no bootstrap directive. What we are doing
    instead is calling the bootstrap function and passing in the root application
    component. By convention, root component is called 'AppComponent'.
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: In Angular 2, what is the name of the root component?
- !Sample
  answer: Observables are lazy
  article_title: Please move, here comes Angular 2
  context: In Angular 2, services are often used to fetch the data from the server.
    While doing so they use HTTP client that is built in Angular 2. There was a slight
    twist in how the data can be fetched. Just as AngularJS use promises, Angular
    2 uses promises, but wait... Angular 2 new favorite way of getting data is via
    Observables! Now, observables are great. They are a part of Reactive Extensions.
    If you haven't seen them yet, it's time to learn more. But what's the difference
    between promises and observables? Observables are lazy - meaning you have to subscribe
    to them in order to trigger their behavior and you can also cancel your request
    thanks to disposability. Ben Lesh compared them in this great video which is worth
    watching.
  filename: 2016/08/03/Please-Move-Here-Comes-Angular2/index.html
  question: What's the difference between promises and observables?
- !Sample
  answer: chat bots
  article_title: AI - our best friend, or is it?
  context: But the part of using AI Ashley talked about the most were chat bots. Making
    those, brands can make their interactions with users more direct and personal.
    If we just look at the numbers - there are over 900 million Facebook users and
    around 11 000 bots already created. Why? Well, computers are good at remembering
    stuff, automating mundane tasks, and making accurate calculations very fast. And
    when users prompt your bot for information, the response is imminent; they don't
    have to wait for someone to read the message first and then look for the information.
    Of course, there are still skeptics who'd prefer talking to a human as well as
    there are brands unsure of payoff. But if we follow the best practices Ashley
    gave in her talk, we might step in the right direction and make a bot everyone
    would want to use.
  filename: 2016/11/28/WebCamp-2016/index.html
  question: How can brands make their interactions with users more personal?
- !Sample
  answer: visual design
  article_title: AI - our best friend, or is it?
  context: "What we also need to know is how much information is needed - we don't\
    \ want to provide too much nor too little of it. Besides just written content,\
    \ we should think about the visual design of our bot making it more appealing\
    \ to users. And, the one we find really important, always close the loop. The\
    \ user gives you feedback \u2013 thank them, display a message, the user tells\
    \ you what to do, again \u2013 display a message."
  filename: 2016/11/28/WebCamp-2016/index.html
  question: Other than written content, what else should you think about to make your
    bot more appealing to users?
- !Sample
  answer: two-way serial communication line
  article_title: Hacking BMW I-BUS With Raspberry PI
  context: The core of car communication is a bus line - two-way serial communication
    line, with one or two wires for the signal. All cars have multiple bus systems
    that group electronics depending on their use in the car, like CAN-bus, I-bus,
    K-bus, D-bus, etc. We will focus on I-bus (Information Bus) which is used to control
    radio, CD, navigation, interior lights, parking sensors, steering wheel buttons,
    etc. I-Bus can be found on all BMW E39 (5-series 1995-2003), E38 (7-series 1994-2001),
    E46 (3-series 1998-2005), E53 (X5 1999-2006), some Minies under BMW and some Rovers.
  filename: 2016/12/01/hacking-bmw-i-bus-with-raspberry-pi/index.html
  question: What is a bus line?
- !Sample
  answer: I-bus (Information Bus)
  article_title: Hacking BMW I-BUS With Raspberry PI
  context: The core of car communication is a bus line - two-way serial communication
    line, with one or two wires for the signal. All cars have multiple bus systems
    that group electronics depending on their use in the car, like CAN-bus, I-bus,
    K-bus, D-bus, etc. We will focus on I-bus (Information Bus) which is used to control
    radio, CD, navigation, interior lights, parking sensors, steering wheel buttons,
    etc. I-Bus can be found on all BMW E39 (5-series 1995-2003), E38 (7-series 1994-2001),
    E46 (3-series 1998-2005), E53 (X5 1999-2006), some Minies under BMW and some Rovers.
  filename: 2016/12/01/hacking-bmw-i-bus-with-raspberry-pi/index.html
  question: What controls navigation on a BMW?
- !Sample
  answer: with flexbox
  article_title: Building a simple CSS grid with flexbox
  context: "Rather then using \u201Cwe cover all possible scenarios\u201D solutions\
    \ that bring a whole new set of rules and specifics to your workflow, you can\
    \ easily build your own grid, especially if you don't have a need for high complexity.\
    \ In that case, you can create simple CSS grid with flexbox in just a few easy\
    \ steps.  The major advantage of using flexbox over classic floated grid is that\
    \ you have more options for display, but the best feature, in my opinion, is that\
    \ the equal column height problem is solved by default. Since browser support\
    \ is fair (there are a few issues with older versions of IE), we're good to go."
  filename: 2016/12/02/building-a-simple-css-grid-with-flexbox/index.html
  question: How can you build a simple css grid?
- !Sample
  answer: you have more options for display
  article_title: Building a simple CSS grid with flexbox
  context: "Rather then using \u201Cwe cover all possible scenarios\u201D solutions\
    \ that bring a whole new set of rules and specifics to your workflow, you can\
    \ easily build your own grid, especially if you don't have a need for high complexity.\
    \ In that case, you can create simple CSS grid with flexbox in just a few easy\
    \ steps.  The major advantage of using flexbox over classic floated grid is that\
    \ you have more options for display, but the best feature, in my opinion, is that\
    \ the equal column height problem is solved by default. Since browser support\
    \ is fair (there are a few issues with older versions of IE), we're good to go."
  filename: 2016/12/02/building-a-simple-css-grid-with-flexbox/index.html
  question: What is an advantage to using flexbox over a floated grid?
- !Sample
  answer: media query
  article_title: Create print-ready dashboard using CSS
  context: 'In today''s web design, everything is about adapting websites to different
    kinds of devices, and you should be familiar with media queries. In case you''re
    not, a simple definition of media query would be - applying different stylesheets
    depending on device window size. So, a print media query is changing the CSS properties
    of HTML elements in a way we want them to look on paper or in a print mode.  To
    get a better understanding of print CSS, we will use the dashboard as an example.
    Here is how our dashboard looks like on a desktop-sized screen:'
  filename: 2016/12/08/Create-Print-ready-Dashboard-Using-CSS/index.html
  question: How do you apply different stylesheets to different window sizes?
- !Sample
  answer: hide them, or show just the title
  article_title: Create print-ready dashboard using CSS
  context: Here are a few useful tips and tricks when using the print media query.
    As you can guess, elements such as video and audio can not be reproduced on paper.
    The best thing you can do here is to hide them, or show just the title. When using
    different kinds of slideshows, showing just one slide can do the trick. If you
    click here on paper you will not be redirected to a new paper, so showing a full
    URL is a way to go. Another useful feature is a possibility to switch between
    portrait and landscape orientation.
  filename: 2016/12/08/Create-Print-ready-Dashboard-Using-CSS/index.html
  question: When using a print query, what should you do with audio and video?
- !Sample
  answer: a general reusable solution to a commonly occurring problem
  article_title: Unit of Work - a Design Pattern
  context: "A design pattern is a general reusable solution to a commonly occurring\
    \ problem in software development. It cannot be transformed directly into the\
    \ source code as a finished design since it is more of a template that can be\
    \ used in many different situations. Unit of work is one of them - and in this\
    \ post, we\u2019ll explain how to use it and how to implement it in ASP.NET using\
    \ Entity Framework."
  filename: 2017/01/13/unit-of-work-a-design-pattern/index.html
  question: What is a design pattern?
- !Sample
  answer: Unit of Work is handling them all in the TransactionScope
  article_title: Unit of Work - a Design Pattern
  context: "A design pattern is a general reusable solution to a commonly occurring\
    \ problem in software development. It cannot be transformed directly into the\
    \ source code as a finished design since it is more of a template that can be\
    \ used in many different situations. Unit of work is one of them - and in this\
    \ post, we\u2019ll explain how to use it and how to implement it in ASP.NET using\
    \ Entity Framework."
  filename: 2017/01/13/unit-of-work-a-design-pattern/index.html
  question: How does unit of work prevent unfinished requests from changing data?
- !Sample
  answer: a single manageable item
  article_title: Introduction to Azure Resource Manager
  context: "Before we dive deeper into ARM features, it\u2019s important to understand\
    \ the terminology.  A Resource is a single manageable item available through Azure,\
    \ for example, a database, load balancer, virtual network, virtual machine, storage\
    \ account, etc.  A Resource Group is a container that holds related resources.\
    \  A Resource Manager (ARM) template is a JSON file that defines resources to\
    \ be deployed to a Resource Group."
  filename: 2017/01/27/introduction-to-azure-resource-manager/index.html
  question: What is a resource in ARM?
- !Sample
  answer: working with data sent by the browser
  article_title: Model binding in ASP.NET MVC
  context: Model binding is a mechanism ASP.NET MVC uses to create parameter objects
    defined in controller action methods. The parameters can be of any type, from
    simple to complex ones. It simplifies working with data sent by the browser because
    data is automatically assigned to the specified model. Without this mechanism,
    developers would need to manually assign values to model properties, which would
    result in writing almost the same code in every action method.
  filename: 2017/02/09/model-binding-asp-net-mvc/index.html
  question: What does model binding in ASP.NET MVC simplify?
- !Sample
  answer: Google API Console
  article_title: Google Maps JavaScript API - Intro
  context: "This article will teach you how to use Google Maps JavaScript API, and\
    \ will cover initialization, custom styling, drawing basic shapes, adding markers,\
    \ info window, and using geocoding service.  Map setup First, we need the API\
    \ key (we can get one from Google API Console): Create Google account if you don\u2019\
    t have one.  Create a new project.  Enable Google Maps JavaScript API.  Under\
    \ credentials, create new API key (you can restrict key only to your site)."
  filename: 2017/02/22/google-maps-javascript-api-intro/index.html
  question: Where can you get a google api key?
- !Sample
  answer: the double-submit cookie defense pattern
  article_title: Security in an AngularJS application
  context: AngularJS also provides protection from certain types of attacks if the
    server is compatible and properly configured. Firstly, for those who do not know,
    cookies are domain-specific data that persists when making requests. If cookies
    are being used for authorization between the server and the client, AngularJS
    provides protection from XSRF attacks by using the double-submit cookie defense
    pattern. For example, we can set up our MVC or WebAPI server to send out a cookie
    called XSRF-TOKEN. When AngularJS detects that cookie in the response header,
    it creates a custom X-XSRF-TOKEN header with the value of the XSRF-TOKEN cookie.
    The two values are then compared on the server, and if they match, the authorization
    is valid. The attacker cannot trick the browser to send out the custom header
    since it is something AngularJS sends when making legitimate requests from within
    the app.
  filename: 2017/03/13/security-in-an-angularjs-application/index.html
  question: How does angular protect against XSRF?
- !Sample
  answer: A token is not encrypted, but encoded
  article_title: Security in an AngularJS application
  context: "There are a couple of ways of authorizing communication between client\
    \ and server. For one, we can use cookies, but there are plenty of ways to exploit\
    \ them if we\u2019re not careful. The most common way is through the use of tokens,\
    \ which are encoded bits of data containing authorization data, information about\
    \ the user, expiration time, and whatever else we choose to put in it. A token\
    \ is not encrypted, but encoded, so we need to be careful not to put sensitive\
    \ data (like passwords). We will be looking at an example that uses tokens generated\
    \ on the server."
  filename: 2017/03/13/security-in-an-angularjs-application/index.html
  question: Why shouldn't you put sensitive data in a web token?
- !Sample
  answer: Singleton, Scoped, or Transient
  article_title: Dependency Injection in ASP.NET Core
  context: 'Once the services are defined, it is necessary to register the dependencies
    in ConfigureServices method inside the Startup.cs class, so ASP.NET can know about
    them. When declaring a service, in ASP.NET Core context, there are three kinds
    of object lifetimes to choose from: Singleton, Scoped, or Transient. It is important
    to understand how each of them works, so we know which one to use, in what situations.'
  filename: 2017/03/15/di-asp-net-core/index.html
  question: What are the different lifetimes of services in the context of ASP.NET
    Core?
- !Sample
  answer: A logger
  article_title: Dependency Injection in ASP.NET Core
  context: Providing the implementation as a second type parameter will lazy-load
    the service the first time it is requested. Another option, but not a better one,
    would be to create a specific instance of the concrete implementation ourselves,
    inside the ConfigureServices method.  Singletons are useful for resources which
    are shared by the entire application and need to be managed. A logger is used
    as a classic example of a singleton. If we only use one log stream, e.g., console,
    all we need is one logger instance for our outputs.
  filename: 2017/03/15/di-asp-net-core/index.html
  question: What is a good example of a singleton?
- !Sample
  answer: visual design
  article_title: Custom IntelliSense with Monaco Editor
  context: "What we also need to know is how much information is needed - we don\u2019\
    t want to provide too much nor too little of it. Besides just written content,\
    \ we should think about the visual design of our bot making it more appealing\
    \ to users. And, the one we find really important, always close the loop. The\
    \ user gives you feedback \u2013 thank them, display a message, the user tells\
    \ you what to do, again \u2013 display a message."
  filename: 2017/04/11/custom-intellisense-with-monaco-editor/index.html
  question: Other than written content, what else should you think about to make your
    bot more appealing to users?
